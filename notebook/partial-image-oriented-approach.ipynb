{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Bebas Neue; font-size:2em;\">Two Machine Learning Approaches In Skin Lesions Classification - Part 2</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hickle as hkl \n",
    "import seaborn as sb\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Bebas Neue; font-size:2em;\">PARTIAL IMAGE ORIENTED APPROACH</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of using other algorithms borns from the csv file included in the HAM10000 dataset that cannot be used by the CNN. According to dermatologists age of the patient and localization of the skin lesions are very important in the diagnosis, for example some kind of skin moles can be malignant in patients older than 50 years old but they are normal in young people.\n",
    "However those features alone aren't enough for solve the problem, the aspect of the skin lesion is fundamental! So it's necessary previously a work of feature engineering for fusing the most importants pixels of each image to the metadatas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firtsly I define the class PixelManager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelManager:\n",
    "    def __init__(self):\n",
    "        self.metadata = pd.read_csv('dataset/HAM10000_metadata.csv')\n",
    "        self.drop_unknown()\n",
    "        self.undersample_nv()\n",
    "        self.importances = hkl.load(\"importances.hkl\")\n",
    "        self.importances_indexes_sorted = sorted(range(self.importances.size), key=lambda k: self.importances[k], reverse=True)\n",
    "        \n",
    "    def drop_unknown(self):\n",
    "        self.metadata = self.metadata[(self.metadata.sex != 'unknown') & \n",
    "                         (self.metadata.localization != 'unknown')].dropna().reset_index(drop=True)\n",
    "        \n",
    "    def undersample_nv(self):\n",
    "        nv_to_delete = self.metadata[self.metadata[\"dx\"]==\"nv\"][\"image_id\"].sample(4791)\n",
    "        self.metadata = self.metadata.drop(nv_to_delete.index).reset_index(drop=True)\n",
    "        \n",
    "    def get_best_n_pixels(self, n):\n",
    "        return self.importances_indexes_sorted[0:n]\n",
    "    \n",
    "    def get_best_n_pixels_df(self, n):\n",
    "        top_n_pixels = self.importances_indexes_sorted[0:n]\n",
    "        pixel_matrix=[]\n",
    "        for index, row in self.metadata.iterrows():\n",
    "            img = cv2.imread(f\"dataset/{row['dx']}/{row['image_id']}.jpg\")\n",
    "            img_resize = cv2.resize(img,(64,64))\n",
    "            gray = cv2.cvtColor(img_resize,cv2.COLOR_BGR2GRAY)\n",
    "            pixel_matrix.append(gray.reshape(gray.size)[top_n_pixels])\n",
    "        return pd.DataFrame(pixel_matrix, columns=[f\"p{i}\" for i in range(1,n+1)])\n",
    "        \n",
    "    def complete_with_pixels(self,n):\n",
    "        return pd.concat([self.metadata, self.get_best_n_pixels_df(n)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the init I load the metadata csv, and I call the drop_unknown method that drops the 254 rows with NaN or unknown values (I decided to simply drop them because they aren't too much) and the undersample_nv method that, as in the first approach, undersample the \"nv\" class to have 1700 instances.  \n",
    "  \n",
    "Furthermore PixelManager has the get_best_n_pixels method that take in input an integer n and gives in output an array with the indexes of the n most important pixels and the get_best_n_pixels_df that returns a DataFrame containing values of the n most important pixels of each image of the HAM10000 dataset.  \n",
    "Finally the complete_with_pixels method return the union between the best n pixels DataFrame and the metadata DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_manager = PixelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look, for example, what are the 100 most important pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24aa89faa48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top100_pixel = pixel_manager.get_best_n_pixels(100)\n",
    "top100_image = [pixel_manager.importances[i] if i in top100_pixel else 0 for i in range(len(pixel_manager.importances))]\n",
    "sb.heatmap(np.array(top100_image).reshape(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example I'll create the dataset using the 150 best pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_with_pixels = pixel_manager.complete_with_pixels(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>...</th>\n",
       "      <th>p141</th>\n",
       "      <th>p142</th>\n",
       "      <th>p143</th>\n",
       "      <th>p144</th>\n",
       "      <th>p145</th>\n",
       "      <th>p146</th>\n",
       "      <th>p147</th>\n",
       "      <th>p148</th>\n",
       "      <th>p149</th>\n",
       "      <th>p150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>184</td>\n",
       "      <td>172</td>\n",
       "      <td>109</td>\n",
       "      <td>206</td>\n",
       "      <td>164</td>\n",
       "      <td>194</td>\n",
       "      <td>200</td>\n",
       "      <td>166</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>208</td>\n",
       "      <td>175</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>213</td>\n",
       "      <td>193</td>\n",
       "      <td>141</td>\n",
       "      <td>211</td>\n",
       "      <td>143</td>\n",
       "      <td>171</td>\n",
       "      <td>177</td>\n",
       "      <td>63</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>170</td>\n",
       "      <td>177</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>189</td>\n",
       "      <td>168</td>\n",
       "      <td>142</td>\n",
       "      <td>107</td>\n",
       "      <td>182</td>\n",
       "      <td>158</td>\n",
       "      <td>145</td>\n",
       "      <td>135</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>180</td>\n",
       "      <td>171</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>209</td>\n",
       "      <td>153</td>\n",
       "      <td>134</td>\n",
       "      <td>157</td>\n",
       "      <td>153</td>\n",
       "      <td>179</td>\n",
       "      <td>162</td>\n",
       "      <td>52</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>202</td>\n",
       "      <td>194</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>167</td>\n",
       "      <td>216</td>\n",
       "      <td>164</td>\n",
       "      <td>186</td>\n",
       "      <td>167</td>\n",
       "      <td>93</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033084</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>160</td>\n",
       "      <td>153</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>194</td>\n",
       "      <td>178</td>\n",
       "      <td>130</td>\n",
       "      <td>88</td>\n",
       "      <td>143</td>\n",
       "      <td>113</td>\n",
       "      <td>118</td>\n",
       "      <td>206</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033550</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>133</td>\n",
       "      <td>131</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>170</td>\n",
       "      <td>114</td>\n",
       "      <td>99</td>\n",
       "      <td>153</td>\n",
       "      <td>128</td>\n",
       "      <td>97</td>\n",
       "      <td>164</td>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033536</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>149</td>\n",
       "      <td>188</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>214</td>\n",
       "      <td>183</td>\n",
       "      <td>108</td>\n",
       "      <td>141</td>\n",
       "      <td>156</td>\n",
       "      <td>137</td>\n",
       "      <td>156</td>\n",
       "      <td>95</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>180</td>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>177</td>\n",
       "      <td>140</td>\n",
       "      <td>159</td>\n",
       "      <td>169</td>\n",
       "      <td>140</td>\n",
       "      <td>144</td>\n",
       "      <td>152</td>\n",
       "      <td>175</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>145</td>\n",
       "      <td>112</td>\n",
       "      <td>109</td>\n",
       "      <td>154</td>\n",
       "      <td>184</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4970 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id     dx dx_type   age     sex localization  \\\n",
       "0     HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp   \n",
       "1     HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp   \n",
       "2     HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp   \n",
       "3     HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp   \n",
       "4     HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear   \n",
       "...           ...           ...    ...     ...   ...     ...          ...   \n",
       "4965  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen   \n",
       "4966  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen   \n",
       "4967  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen   \n",
       "4968  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face   \n",
       "4969  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back   \n",
       "\n",
       "       p1   p2   p3  ...  p141  p142  p143  p144  p145  p146  p147  p148  \\\n",
       "0     174  179  163  ...   203   184   172   109   206   164   194   200   \n",
       "1     208  175  191  ...   169   213   193   141   211   143   171   177   \n",
       "2     170  177  173  ...   168   189   168   142   107   182   158   145   \n",
       "3     180  171  177  ...   164   209   153   134   157   153   179   162   \n",
       "4     202  194  189  ...   160   167   216   164   186   167    93   168   \n",
       "...   ...  ...  ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "4965  160  153  172  ...   128   194   178   130    88   143   113   118   \n",
       "4966  133  131  135  ...   159   170   114    99   153   128    97   164   \n",
       "4967  149  188  145  ...   187   214   183   108   141   156   137   156   \n",
       "4968  180  153  171  ...   143   177   140   159   169   140   144   152   \n",
       "4969   75   53   73  ...   159   134   133   129   145   112   109   154   \n",
       "\n",
       "      p149  p150  \n",
       "0      166   135  \n",
       "1       63   162  \n",
       "2      135   156  \n",
       "3       52   192  \n",
       "4      177   130  \n",
       "...    ...   ...  \n",
       "4965   206   139  \n",
       "4966    40   155  \n",
       "4967    95   169  \n",
       "4968   175   144  \n",
       "4969   184   123  \n",
       "\n",
       "[4970 rows x 157 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_with_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I get features and target features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = metadata_with_pixels[\"dx\"]\n",
    "X = metadata_with_pixels.drop(['lesion_id','image_id','dx_type','dx'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I One-Hot encode categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(series): \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(series)\n",
    "    return encoder, pd.DataFrame(encoder.transform(series).toarray(), columns=encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoder, sex_loc_encoded = one_hot_encoder(X[[\"sex\",\"localization\"]])\n",
    "X_encoded = pd.concat([sex_loc_encoded, X.drop([\"sex\",\"localization\"], inplace=False, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_female</th>\n",
       "      <th>x0_male</th>\n",
       "      <th>x1_abdomen</th>\n",
       "      <th>x1_acral</th>\n",
       "      <th>x1_back</th>\n",
       "      <th>x1_chest</th>\n",
       "      <th>x1_ear</th>\n",
       "      <th>x1_face</th>\n",
       "      <th>x1_foot</th>\n",
       "      <th>x1_genital</th>\n",
       "      <th>...</th>\n",
       "      <th>p141</th>\n",
       "      <th>p142</th>\n",
       "      <th>p143</th>\n",
       "      <th>p144</th>\n",
       "      <th>p145</th>\n",
       "      <th>p146</th>\n",
       "      <th>p147</th>\n",
       "      <th>p148</th>\n",
       "      <th>p149</th>\n",
       "      <th>p150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>184</td>\n",
       "      <td>172</td>\n",
       "      <td>109</td>\n",
       "      <td>206</td>\n",
       "      <td>164</td>\n",
       "      <td>194</td>\n",
       "      <td>200</td>\n",
       "      <td>166</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>213</td>\n",
       "      <td>193</td>\n",
       "      <td>141</td>\n",
       "      <td>211</td>\n",
       "      <td>143</td>\n",
       "      <td>171</td>\n",
       "      <td>177</td>\n",
       "      <td>63</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>189</td>\n",
       "      <td>168</td>\n",
       "      <td>142</td>\n",
       "      <td>107</td>\n",
       "      <td>182</td>\n",
       "      <td>158</td>\n",
       "      <td>145</td>\n",
       "      <td>135</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>209</td>\n",
       "      <td>153</td>\n",
       "      <td>134</td>\n",
       "      <td>157</td>\n",
       "      <td>153</td>\n",
       "      <td>179</td>\n",
       "      <td>162</td>\n",
       "      <td>52</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>167</td>\n",
       "      <td>216</td>\n",
       "      <td>164</td>\n",
       "      <td>186</td>\n",
       "      <td>167</td>\n",
       "      <td>93</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>194</td>\n",
       "      <td>178</td>\n",
       "      <td>130</td>\n",
       "      <td>88</td>\n",
       "      <td>143</td>\n",
       "      <td>113</td>\n",
       "      <td>118</td>\n",
       "      <td>206</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>170</td>\n",
       "      <td>114</td>\n",
       "      <td>99</td>\n",
       "      <td>153</td>\n",
       "      <td>128</td>\n",
       "      <td>97</td>\n",
       "      <td>164</td>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>214</td>\n",
       "      <td>183</td>\n",
       "      <td>108</td>\n",
       "      <td>141</td>\n",
       "      <td>156</td>\n",
       "      <td>137</td>\n",
       "      <td>156</td>\n",
       "      <td>95</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>177</td>\n",
       "      <td>140</td>\n",
       "      <td>159</td>\n",
       "      <td>169</td>\n",
       "      <td>140</td>\n",
       "      <td>144</td>\n",
       "      <td>152</td>\n",
       "      <td>175</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>145</td>\n",
       "      <td>112</td>\n",
       "      <td>109</td>\n",
       "      <td>154</td>\n",
       "      <td>184</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4970 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x0_female  x0_male  x1_abdomen  x1_acral  x1_back  x1_chest  x1_ear  \\\n",
       "0           0.0      1.0         0.0       0.0      0.0       0.0     0.0   \n",
       "1           0.0      1.0         0.0       0.0      0.0       0.0     0.0   \n",
       "2           0.0      1.0         0.0       0.0      0.0       0.0     0.0   \n",
       "3           0.0      1.0         0.0       0.0      0.0       0.0     0.0   \n",
       "4           0.0      1.0         0.0       0.0      0.0       0.0     1.0   \n",
       "...         ...      ...         ...       ...      ...       ...     ...   \n",
       "4965        0.0      1.0         1.0       0.0      0.0       0.0     0.0   \n",
       "4966        0.0      1.0         1.0       0.0      0.0       0.0     0.0   \n",
       "4967        0.0      1.0         1.0       0.0      0.0       0.0     0.0   \n",
       "4968        0.0      1.0         0.0       0.0      0.0       0.0     0.0   \n",
       "4969        1.0      0.0         0.0       0.0      1.0       0.0     0.0   \n",
       "\n",
       "      x1_face  x1_foot  x1_genital  ...  p141  p142  p143  p144  p145  p146  \\\n",
       "0         0.0      0.0         0.0  ...   203   184   172   109   206   164   \n",
       "1         0.0      0.0         0.0  ...   169   213   193   141   211   143   \n",
       "2         0.0      0.0         0.0  ...   168   189   168   142   107   182   \n",
       "3         0.0      0.0         0.0  ...   164   209   153   134   157   153   \n",
       "4         0.0      0.0         0.0  ...   160   167   216   164   186   167   \n",
       "...       ...      ...         ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "4965      0.0      0.0         0.0  ...   128   194   178   130    88   143   \n",
       "4966      0.0      0.0         0.0  ...   159   170   114    99   153   128   \n",
       "4967      0.0      0.0         0.0  ...   187   214   183   108   141   156   \n",
       "4968      1.0      0.0         0.0  ...   143   177   140   159   169   140   \n",
       "4969      0.0      0.0         0.0  ...   159   134   133   129   145   112   \n",
       "\n",
       "      p147  p148  p149  p150  \n",
       "0      194   200   166   135  \n",
       "1      171   177    63   162  \n",
       "2      158   145   135   156  \n",
       "3      179   162    52   192  \n",
       "4       93   168   177   130  \n",
       "...    ...   ...   ...   ...  \n",
       "4965   113   118   206   139  \n",
       "4966    97   164    40   155  \n",
       "4967   137   156    95   169  \n",
       "4968   144   152   175   144  \n",
       "4969   109   154   184   123  \n",
       "\n",
       "[4970 rows x 167 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I smote the dataset for balance it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_smote, y_smote = sm.fit_resample(X_encoded, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I fix the smoted dataset putting 1 at the argmax of each cathegorical feature and 0 at the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator(m,n):\n",
    "    arr=np.zeros(m)\n",
    "    arr[n]=1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_sex_df = pd.DataFrame([indicator(2,np.argmax(row)) for row in X_smote[X_smote.columns[0:2]].to_numpy()],\n",
    "                            columns=X_smote.columns[0:2])\n",
    "smote_local_df = pd.DataFrame([indicator(14,np.argmax(row)) for row in X_smote[X_smote.columns[2:16]].to_numpy()],\n",
    "                              columns=X_smote.columns[2:16])\n",
    "X_norm = pd.concat([smote_sex_df, X_smote.drop(X_smote.columns[0:16], axis=1, inplace=False), smote_local_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I normalize pixels and age features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm[[f\"p{i}\" for i in range(1,151)]] /= 255\n",
    "X_norm[\"age\"] /= np.max(X_norm[\"age\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_female</th>\n",
       "      <th>x0_male</th>\n",
       "      <th>age</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>...</th>\n",
       "      <th>x1_ear</th>\n",
       "      <th>x1_face</th>\n",
       "      <th>x1_foot</th>\n",
       "      <th>x1_genital</th>\n",
       "      <th>x1_hand</th>\n",
       "      <th>x1_lower extremity</th>\n",
       "      <th>x1_neck</th>\n",
       "      <th>x1_scalp</th>\n",
       "      <th>x1_trunk</th>\n",
       "      <th>x1_upper extremity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569296</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542769</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454956</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11898</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749185</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661571</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11900 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0_female  x0_male       age        p1        p2        p3        p4  \\\n",
       "0            0.0      1.0  0.941176  0.682353  0.701961  0.639216  0.588235   \n",
       "1            0.0      1.0  0.941176  0.815686  0.686275  0.749020  0.580392   \n",
       "2            0.0      1.0  0.941176  0.666667  0.694118  0.678431  0.698039   \n",
       "3            0.0      1.0  0.941176  0.705882  0.670588  0.694118  0.729412   \n",
       "4            0.0      1.0  0.882353  0.792157  0.760784  0.741176  0.701961   \n",
       "...          ...      ...       ...       ...       ...       ...       ...   \n",
       "11895        1.0      0.0  0.569296  0.329412  0.380392  0.352941  0.372549   \n",
       "11896        1.0      0.0  0.542769  0.533333  0.439216  0.498039  0.482353   \n",
       "11897        1.0      0.0  0.454956  0.419608  0.258824  0.231373  0.219608   \n",
       "11898        1.0      0.0  0.749185  0.435294  0.384314  0.364706  0.352941   \n",
       "11899        0.0      1.0  0.661571  0.501961  0.545098  0.517647  0.549020   \n",
       "\n",
       "             p5        p6        p7  ...  x1_ear  x1_face  x1_foot  \\\n",
       "0      0.611765  0.615686  0.686275  ...     0.0      0.0      0.0   \n",
       "1      0.709804  0.643137  0.717647  ...     0.0      0.0      0.0   \n",
       "2      0.639216  0.670588  0.698039  ...     0.0      0.0      0.0   \n",
       "3      0.709804  0.725490  0.635294  ...     0.0      0.0      0.0   \n",
       "4      0.733333  0.733333  0.701961  ...     1.0      0.0      0.0   \n",
       "...         ...       ...       ...  ...     ...      ...      ...   \n",
       "11895  0.376471  0.384314  0.384314  ...     0.0      0.0      0.0   \n",
       "11896  0.431373  0.431373  0.435294  ...     0.0      0.0      0.0   \n",
       "11897  0.243137  0.196078  0.231373  ...     0.0      0.0      0.0   \n",
       "11898  0.286275  0.294118  0.372549  ...     0.0      0.0      0.0   \n",
       "11899  0.552941  0.549020  0.525490  ...     0.0      0.0      0.0   \n",
       "\n",
       "       x1_genital  x1_hand  x1_lower extremity  x1_neck  x1_scalp  x1_trunk  \\\n",
       "0             0.0      0.0                 0.0      0.0       1.0       0.0   \n",
       "1             0.0      0.0                 0.0      0.0       1.0       0.0   \n",
       "2             0.0      0.0                 0.0      0.0       1.0       0.0   \n",
       "3             0.0      0.0                 0.0      0.0       1.0       0.0   \n",
       "4             0.0      0.0                 0.0      0.0       0.0       0.0   \n",
       "...           ...      ...                 ...      ...       ...       ...   \n",
       "11895         0.0      0.0                 0.0      0.0       0.0       0.0   \n",
       "11896         0.0      0.0                 0.0      0.0       0.0       0.0   \n",
       "11897         0.0      0.0                 0.0      0.0       0.0       0.0   \n",
       "11898         0.0      0.0                 0.0      0.0       0.0       0.0   \n",
       "11899         0.0      0.0                 0.0      0.0       0.0       1.0   \n",
       "\n",
       "       x1_upper extremity  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "...                   ...  \n",
       "11895                 0.0  \n",
       "11896                 0.0  \n",
       "11897                 0.0  \n",
       "11898                 0.0  \n",
       "11899                 0.0  \n",
       "\n",
       "[11900 rows x 167 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I build a label encoded version of the dataset that I'll use later for computing features importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_loc_column = [x for x in smote_sex_df.columns]\n",
    "for i in smote_local_df.columns:\n",
    "    sex_loc_column.append(i)\n",
    "X_le_only = oh_encoder.inverse_transform(X_norm[sex_loc_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_sex_df = pd.DataFrame(X_le_only, columns=[\"sex\", \"localization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_le = pd.concat([loc_sex_df, X_norm.drop([x for x in X_norm.columns if \"x\" in x], axis=1, inplace=False)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X_le[\"sex\"] = le.fit(X_le[\"sex\"]).transform(X_le[\"sex\"])\n",
    "X_le[\"localization\"] = le.fit(X_le[\"localization\"]).transform(X_le[\"localization\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally I get training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_smote, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning number of tree, max depth of each tree and max features used for splitting, I obtained the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=240, n_jobs=-1, max_depth=70, max_features=40, criterion=\"entropy\")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.88      0.95      0.91       333\n",
      "         bcc       0.88      0.94      0.91       338\n",
      "         bkl       0.74      0.70      0.72       328\n",
      "          df       0.92      1.00      0.96       301\n",
      "         mel       0.75      0.67      0.71       375\n",
      "          nv       0.77      0.72      0.74       362\n",
      "        vasc       0.96      0.99      0.97       343\n",
      "\n",
      "    accuracy                           0.85      2380\n",
      "   macro avg       0.84      0.85      0.85      2380\n",
      "weighted avg       0.84      0.85      0.84      2380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning number of estimators and max depth of each tree, I obtained the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_classifier = tree.DecisionTreeClassifier(max_depth=15)\n",
    "ada = AdaBoostClassifier(algorithm='SAMME', base_estimator=weak_classifier, random_state=1, n_estimators=150)\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.91      0.96      0.93       333\n",
      "         bcc       0.89      0.96      0.92       338\n",
      "         bkl       0.75      0.75      0.75       328\n",
      "          df       0.96      1.00      0.98       301\n",
      "         mel       0.78      0.67      0.72       375\n",
      "          nv       0.74      0.72      0.73       362\n",
      "        vasc       0.99      0.98      0.98       343\n",
      "\n",
      "    accuracy                           0.86      2380\n",
      "   macro avg       0.86      0.86      0.86      2380\n",
      "weighted avg       0.85      0.86      0.85      2380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning class weights and choose the best kernel, I obtained the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {'akiec': 100,'bcc': 100,'bkl': 250.0,'df': 100,'mel': 250.0,'nv': 250.0,'vasc': 100}\n",
    "svc = SVC(class_weight=class_weights)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.92      0.98      0.94       333\n",
      "         bcc       0.87      0.97      0.92       338\n",
      "         bkl       0.72      0.81      0.76       328\n",
      "          df       0.96      1.00      0.98       301\n",
      "         mel       0.79      0.69      0.74       375\n",
      "          nv       0.84      0.65      0.73       362\n",
      "        vasc       0.97      1.00      0.98       343\n",
      "\n",
      "    accuracy                           0.86      2380\n",
      "   macro avg       0.86      0.87      0.86      2380\n",
      "weighted avg       0.86      0.86      0.86      2380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I do a Kfold cross validation for each model and I compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KFold 1 for RandomForestClassifier\n",
      "Starting KFold 2 for RandomForestClassifier\n",
      "Starting KFold 3 for RandomForestClassifier\n",
      "Starting KFold 4 for RandomForestClassifier\n",
      "Starting KFold 1 for AdaBoostClassifier\n",
      "Starting KFold 2 for AdaBoostClassifier\n",
      "Starting KFold 3 for AdaBoostClassifier\n",
      "Starting KFold 4 for AdaBoostClassifier\n",
      "Starting KFold 1 for SVC\n",
      "Starting KFold 2 for SVC\n",
      "Starting KFold 3 for SVC\n",
      "Starting KFold 4 for SVC\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "kfold_accuracies = dict()\n",
    "iteration = 0\n",
    "for model in [rf, ada, svc]:\n",
    "    iteration = 0\n",
    "    model_name = str(model).split(\"(\")[0]\n",
    "    kfold_accuracies[model_name] = list()\n",
    "    for train_index, test_index in kf.split(X_norm.to_numpy()):\n",
    "        iteration += 1\n",
    "        print(f\"Starting KFold {iteration} for {model_name}\")\n",
    "        model.fit(X_norm.to_numpy()[train_index], y_smote.to_numpy()[train_index])\n",
    "        accuracy = accuracy_score(model.predict(X_norm.to_numpy()[test_index]),y_smote.to_numpy()[test_index])\n",
    "        kfold_accuracies[model_name].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the results computing the mean of each model's accuracy in the four KFold splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "splot = sb.barplot(y=[np.mean(kfold_accuracies[model]) for model in kfold_accuracies.keys()], x=list(kfold_accuracies.keys()))\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(),'.3f'), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha='center', va='center', xytext=(0,5), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remembering CNN KFold accuracy was 0.842, Random Forest model have similar accuracy but AdaBoost and mostly Support Vector Machines overperform the full image oriented approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I conclude the analysis looking at the features importance computed training the tuned Random Forest with the label encoded dataset defined previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Features')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance_tree = RandomForestClassifier(n_estimators=440, n_jobs=-1, max_depth=70, max_features=40)\n",
    "importance_tree.fit(X_le, y_smote)\n",
    "feature_imp = pd.Series(importance_tree.feature_importances_, index=X_le.columns).sort_values(ascending=False)\n",
    "imp=pd.DataFrame(feature_imp)\n",
    "sb.barplot(x=feature_imp[:5], y=feature_imp.index[:5])\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I expected, \"localization\" and \"age\" are incredibly heavy in the classification task.  \n",
    "So, doing a more careful feature engineering made non deep methods (with also a great dimensionality reduction since these algorithms were trained on 167 features instead of 64*64 = 4096) overperform CNN in a image classification task!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
